{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from scipy.fftpack import fft\n",
    "from IPython.display import display\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy import stats\n",
    "import pywt\n",
    "import scipy.stats\n",
    "import re\n",
    "import datetime as dt\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "sns.set_style(\"whitegrid\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy import signal\n",
    "import itertools\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "np. set_printoptions(threshold=np. inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f67700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "    #create the empty list for the files\n",
    "    file_list = []\n",
    "    \n",
    "    #find all files within the seizure prediction directory\n",
    "    for name in glob.glob(directory+'/*'):\n",
    "        #add all file names to list \n",
    "        file_list.append(name)\n",
    "    \n",
    "    #shuffle list \n",
    "    random.shuffle(file_list)\n",
    "    \n",
    "    sampled_list = file_list\n",
    "    \n",
    "    train_list, test_list = train_test_split(sampled_list, test_size=.20, random_state=33)\n",
    "    \n",
    "  \n",
    "    return train_list, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_statistics(list_values):\n",
    "    maximum = np.amax(list_values)\n",
    "    minimum = np.amin(list_values)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    sk = skew(list_values)\n",
    "    return [maximum, minimum, mean, std, sk]\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.where(np.diff(np.sign(list_values)))[0]\n",
    "    zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    mean_crossings = len(mean_crossing_indices)\n",
    "    return [zero_crossings, mean_crossings]\n",
    "\n",
    "\n",
    "def get_features(list_values):\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return crossings + statistics\n",
    "\n",
    "\n",
    "def get_eeg_features(dataset, waveletname,level):\n",
    "    data = dataset.copy()\n",
    "    eeg_features = []\n",
    "\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "            \n",
    "            for array in range(0,len(dataset)):\n",
    "                features = []\n",
    "                signal = dataset[signal_no]\n",
    "                list_coeff = pywt.wavedec(signal, waveletname, level=level)\n",
    "                \n",
    "                for coeff in list_coeff:  \n",
    "                    features += get_features(coeff)\n",
    "            eeg_features.append(features)\n",
    "    X = np.array(eeg_features)\n",
    "    X = X.flatten()\n",
    "    X = X.tolist()\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def get_labels(number):\n",
    "    num = [\"%02d\" % i for i in range(number)]\n",
    "    num.append(\"approx\")\n",
    "    num.reverse()\n",
    "    var = []\n",
    "    e_num = [\"%02d\" % i for i in range(15)]\n",
    "    electrode = 15\n",
    "    labels=[]\n",
    "    e_string = \"electrode_\"\n",
    "    cols=[]\n",
    "                \n",
    "\n",
    "    for e in range(electrode):\n",
    "        \n",
    "        for i in num:\n",
    "            feat = ['zero_crossings','mean_crossings','max', 'min', 'mean', 'sd', 'skew']\n",
    "            for f in feat:\n",
    "                var += [ e_string+str(e)+\"_\"+ f + \"_\" + str(i) ]\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    var.append('y')\n",
    "\n",
    "    return var\n",
    "\n",
    "\n",
    "def get_corr_labels(electrode):\n",
    "   \n",
    "    \n",
    "    v = []\n",
    "    e_num = [\"%02d\" % i for i in range(15)]\n",
    "    labels=[]\n",
    "    e_string = \"e_\"\n",
    "    cols=[]\n",
    "                \n",
    "\n",
    "    for e in range(electrode):\n",
    "        for num in e_num:\n",
    "            v += [ e_string+str(num)+\"_\"+\n",
    "                  e_string+str(e)+\"_corr\" ]\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_list):\n",
    "    start = time.time()\n",
    "    data_df = pd.DataFrame()\n",
    "    signal_df = pd.DataFrame()\n",
    "    dict_eeg_data = defaultdict(list)\n",
    "    dict_eeg_corr = defaultdict(list)\n",
    "    \n",
    "    for filename in file_list:\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        #get patient name \n",
    "        pattern = '^([^_]*_){2}'\n",
    "        splice = (filename.rsplit('/', 1)[-1])\n",
    "        patient = (re.match(pattern, splice)).group(0)\n",
    "\n",
    "        #get segment type\n",
    "        pattern = '^([^_]*_){3}'\n",
    "        splice = (filename.rsplit('/', 1)[-1])\n",
    "        segment = ((re.match(pattern, splice)).group(1)).replace(\"_\", \"\")\n",
    "        \n",
    "        #get file number\n",
    "        file_number = (filename.split(\".\"))[1][-4:].lstrip(\"0\")\n",
    "        \n",
    "        #generate file name\n",
    "        name = segment + \"_segment_\" + file_number\n",
    "\n",
    "        #get recording number \n",
    "        recording = (filename.rsplit('/', 1)[-1])[-8:-4]\n",
    "        \n",
    "        \n",
    "        \n",
    "        electrodes = 15\n",
    "\n",
    "        #load data using loadmat\n",
    "        eeg_data = sio.loadmat(filename)\n",
    "\n",
    "        #create a dictionary to hold the data\n",
    "        \n",
    "        eeg_signals = []\n",
    "        #create a range from the number of electrodes to access files\n",
    "        for i in list(range(electrodes)):\n",
    "\n",
    "            #access each array by electrode index number\n",
    "            \n",
    "            eeg_signal = (signal.resample((eeg_data[name][0][0][0][i]),239400))\n",
    "            eeg_signals.append(eeg_signal)\n",
    "            \n",
    "            #decompose signals and get coeff\n",
    "            \n",
    "            eeg_feat = get_eeg_features(eeg_signals, 'db3', 5)\n",
    "            \n",
    "        #eeg_data_list.append(eeg_feat)\n",
    "            \n",
    "            eeg_feat.append(segment)\n",
    "        #access each electrode name by electrode index number \n",
    "        file_labels = [str(patient)  + str(recording) +  \"_\" + segment]\n",
    "        #eeg_labels_ = eeg_data[name][0][0][3][0][i]\n",
    "        for label in file_labels:\n",
    "            #append data from eeg_data to dictionary using electrode name as label\n",
    "                dict_eeg_data[label].append(eeg_feat)\n",
    "                \n",
    "        eeg_signals = []      \n",
    "        \n",
    "        for i in list(range(electrodes)):\n",
    "\n",
    "            #access each array by electrode index number\n",
    "            \n",
    "            eeg_signal = (signal.resample((eeg_data[name][0][0][0][i]),239400))\n",
    "            eeg_signals.append(eeg_signal)\n",
    "            \n",
    "            #get correlation coeff\n",
    "            \n",
    "            eeg_corr = np.corrcoef(eeg_signals)\n",
    "       \n",
    "            \n",
    "        \n",
    "        #access each electrode name by electrode index number \n",
    "        file_labels = [str(patient)  + str(recording) +  \"_\" + segment]\n",
    "        \n",
    "        #flatten array\n",
    "        eeg_corr = eeg_corr.flatten()\n",
    "    \n",
    "    \n",
    "        for label in file_labels:\n",
    "            #append data from eeg_data to dictionary using electrode name as label\n",
    "                dict_eeg_corr[label].append(eeg_corr)\n",
    "                \n",
    "        #create df from correlations \n",
    "        corr_df = pd.DataFrame(dict_eeg_corr).T.reset_index()\n",
    "        c = pd.concat([corr_df[0].apply(pd.Series)], axis=1)\n",
    "        \n",
    "        #create col names\n",
    "        corr_cols = get_corr_labels(15)\n",
    "        c.columns = corr_cols\n",
    "        c['Recording'] = corr_df['index']\n",
    "        \n",
    "                 #reorder columns\n",
    "        c_cols = list(c.columns)\n",
    "        c_cols = [c_cols[-1]] + c_cols[:-1]\n",
    "        c = c[c_cols]\n",
    "        \n",
    "#         #drop correlation e00 with e00\n",
    "#         c=c.drop('e_0_corr', axis=1)\n",
    "        \n",
    "        #create df from signal coeff\n",
    "        df = pd.DataFrame(dict_eeg_data).T.reset_index()\n",
    "        x = pd.concat([df[0].apply(pd.Series)], axis=1)\n",
    "        \n",
    "        #name signal coeff columns\n",
    "        column_names=get_labels(5)\n",
    "        x.columns = column_names\n",
    "        x['Recording'] = df['index']\n",
    "        \n",
    "        \n",
    "           #reorder columns\n",
    "        cols = list(x.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        x = x[cols]\n",
    "        \n",
    "        #combine df\n",
    "        results = pd.merge(c,x,on='Recording')\n",
    "    \n",
    "    end=time.time()\n",
    "    print(\"This took: \"+ str(end-start))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create file list for train and test\n",
    "final_test_list = get_files(\"./test_set/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = get_data(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train data \n",
    "final_test_df.to_csv(\"final_test_full_corr.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71c7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
